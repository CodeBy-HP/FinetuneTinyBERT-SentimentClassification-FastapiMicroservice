{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "REJST6u-PazK"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Suppress Warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/IMDB-Dataset.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Load and Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['review', 'sentiment'],\n",
              "        num_rows: 35000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['review', 'sentiment'],\n",
              "        num_rows: 15000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = Dataset.from_pandas(data)\n",
        "dataset = dataset.train_test_split(test_size=0.3)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Check Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    25000\n",
              "negative    25000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 35000/35000 [00:02<00:00, 11773.67 examples/s]\n",
            "Map: 100%|██████████| 15000/15000 [00:01<00:00, 12074.18 examples/s]\n"
          ]
        }
      ],
      "source": [
        "label2id = {'negative': 0, 'positive': 1}\n",
        "id2label = {0:'negative', 1:'positive'}\n",
        "\n",
        "dataset = dataset.map(lambda x: {'label': label2id[x['sentiment']]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'review': 'I saw this film numerous times in the late 60\\'s/early 70\\'s whenever it reared it\\'s head like a reindeer with rabies every November-December as a Saturday matinée kiddie show.It was always stiff competition for THE CHRSTMAS THAT ALMOST WASN\\'T (oops-can I SAY \"Christmas\"?), perhaps the greatest,most iconic Christmas-season film of all time.But that\\'s another review.<br /><br />At the time,I marveled that the on-screen tint of SANTA CLAUS was almost \"pink and white\", so much had the color of the sprocket-torn prints changed color.<br /><br />The film is kinda creepy! I thought so then--and still do, actually. I was highly entertained then, as I still am! It\\'s amusing in a \"retarted-elf\" sort of way. By the way,the image quality looks much better on the DVD I have now than it did in the theater, circa 1969-74.<br /><br />If you are expecting maybe \"the lost RANKIN-BASS Christmas special-forget it! If you want FELLINI DOES Christmas--read on...<br /><br />By nature, the dubbing on these foreign films (the original version here was in Spanish)always makes them seem \"surreal\". This adds to the films inherent oddness. It is also pretty scary in that a \"mishevious demon\" (as described in the original US trailer) spends the entire film trying to turn decent kids \"evil\". One particularly nightmarish scene has a young \"latch-key\" boy wishing he had parents for Christmas-suddenly the \"port-a-family\" emerges out of giant \"Christmas presents-of-the-mind\" until he realizes he\\'s just daydreaming! See this,Christmas lovers--and if you\\'re a stoner, save your stash--this film will make you think you\\'re hallucinating...without drugs!',\n",
              " 'sentiment': 'negative',\n",
              " 'label': 0}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Setup Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model_ckpt = 'huawei-noah/TinyBERT_General_4L_312D'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Tokenize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 35000/35000 [00:25<00:00, 1356.30 examples/s]\n",
            "Map: 100%|██████████| 15000/15000 [00:07<00:00, 2026.17 examples/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer(dataset['train'][0]['review'])\n",
        "\n",
        "def tokenize(batch):\n",
        "    temp = tokenizer(batch['review'], padding=True, truncation=True, max_length=300)\n",
        "    return temp\n",
        "\n",
        "dataset = dataset.map(tokenize, batched=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['review', 'sentiment', 'label', 'input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. Define Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10. Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=len(label2id), label2id=label2id, id2label=id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11. Configure Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir='train_dir',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    evaluation_strategy='epoch'\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['test'],\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 12. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 500/3282 [03:32<20:17,  2.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4625, 'grad_norm': 17.964859008789062, 'learning_rate': 1.695307739183425e-05, 'epoch': 0.46}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 1000/3282 [09:34<31:06,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3519, 'grad_norm': 13.26689338684082, 'learning_rate': 1.3906154783668494e-05, 'epoch': 0.91}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \n",
            " 33%|███▎      | 1094/3282 [13:07<27:38,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3114200234413147, 'eval_accuracy': 0.8658666666666667, 'eval_runtime': 135.0101, 'eval_samples_per_second': 111.103, 'eval_steps_per_second': 3.474, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 1500/3282 [18:43<24:33,  1.21it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3062, 'grad_norm': 22.937177658081055, 'learning_rate': 1.0859232175502743e-05, 'epoch': 1.37}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 2000/3282 [25:34<17:16,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2882, 'grad_norm': 9.670245170593262, 'learning_rate': 7.81230956733699e-06, 'epoch': 1.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \n",
            " 67%|██████▋   | 2188/3282 [30:15<13:21,  1.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.30997201800346375, 'eval_accuracy': 0.8687333333333334, 'eval_runtime': 129.4258, 'eval_samples_per_second': 115.897, 'eval_steps_per_second': 3.624, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 2500/3282 [34:28<10:31,  1.24it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2726, 'grad_norm': 10.428123474121094, 'learning_rate': 4.765386959171238e-06, 'epoch': 2.29}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 3000/3282 [41:15<03:43,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2507, 'grad_norm': 8.650588035583496, 'learning_rate': 1.7184643510054846e-06, 'epoch': 2.74}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \n",
            "100%|██████████| 3282/3282 [47:21<00:00,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2992258071899414, 'eval_accuracy': 0.8818666666666667, 'eval_runtime': 137.2786, 'eval_samples_per_second': 109.267, 'eval_steps_per_second': 3.416, 'epoch': 3.0}\n",
            "{'train_runtime': 2841.0051, 'train_samples_per_second': 36.959, 'train_steps_per_second': 1.155, 'train_loss': 0.31575205847666366, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3282, training_loss=0.31575205847666366, metrics={'train_runtime': 2841.0051, 'train_samples_per_second': 36.959, 'train_steps_per_second': 1.155, 'total_flos': 882184338000000.0, 'train_loss': 0.31575205847666366, 'epoch': 3.0})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13. Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [02:10<00:00,  3.61it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2992258071899414,\n",
              " 'eval_accuracy': 0.8818666666666667,\n",
              " 'eval_runtime': 130.3105,\n",
              " 'eval_samples_per_second': 115.11,\n",
              " 'eval_steps_per_second': 3.599,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 14. Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model('tinybert-sentiment-analysis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 15. Test Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = ['this movie was horrible, the plot was really boring. acting was okay',\n",
        "        'the movie is really sucked. there is not plot and acting was bad',\n",
        "        'what a beautiful movie. great plot. acting was good. will see it again']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\asus\\Desktop\\ml-ops-and-model-deployment-on-aws-main\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9905874133110046},\n",
              " {'label': 'negative', 'score': 0.9908849596977234},\n",
              " {'label': 'positive', 'score': 0.9896246790885925}]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "classifier = pipeline('text-classification', model='tinybert-sentiment-analysis', device=device)\n",
        "\n",
        "classifier(data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Sentiment_Classification_using_BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
